inTrain <- createDataPartition(y = creditcard_data[,target], list = FALSE, p = .8)
train <- creditcard_data[inTrain, ]
test <- creditcard_data[-inTrain, ]
model <- glm(formula =  default.payment.next.month ~.  , family=binomial(link='logit'),data=train)
#lets look at summary of the model
summary(model)
anova(model, test="Chisq")
# Let's see the performance on the test set
fitted.results <- predict(model
,newdata = test[,-25]
# Specifying response means we want the probabilities
,type='response')
confusion
#setting cutoff at 0.5
default.pred1 <- ifelse(fitted.results > 0.5,1,0)
default.pred2 <- ifelse(fitted.results > 0.6,1,0)
confusion2 <- confusionMatrix(data = default.pred2
, reference = test[,target]
, dnn = c("Predicted Default", 'Actual Default'))
confusion1
# Let's use a confusion matrix to evaluate how good our results are
confusion1 <- confusionMatrix(data = default.pred1
, reference = test[,target]
, dnn = c("Predicted Default", 'Actual Default'))
confusion2 <- confusionMatrix(data = default.pred2
, reference = test[,target]
, dnn = c("Predicted Default", 'Actual Default'))
confusion1
#Confusion matrix shows a good accuracy of 81 % with good no information rate of 77 percent and
#p values
confusion2
#setting a higher prob cut off of 0.6 decreased the accuray measure
# Let's look at the ROC curve
library(ROCR)
pr <- prediction(fitted.results, test$default.payment.next.month)
#setting a higher prob cut off of 0.6 decreased the accuray measure
# Let's look at the ROC curve
install.packages("ROCR")
library(ROCR)
pr <- prediction(fitted.results, test$default.payment.next.month)
prf <- performance(pr, measure = "tpr", x.measure = "fpr")
plot(prf)
auc <- performance(pr, measure = "auc")
auc <- auc@y.values[[1]]
auc
#precision recall curves
library('DMwR')
PRcurve(preds = fitted.results, trues = test$default.payment.next.month)
#precision recall curves
install.packages("DMwR")
library('DMwR')
PRcurve(preds = fitted.results, trues = test$default.payment.next.month)
# 6. Using forward selection, determine the best model.
library("ols")
# CSP 571 Homework 4
library(stats)
# 1. Please write a function called backwards() that implements the
# backward selection algorithm using AIC.
model$aic
# 1. Please write a function called backwards() that implements the
# backward selection algorithm using AIC.
model$coefficients
# 1. Please write a function called backwards() that implements the
# backward selection algorithm using AIC.
model['aic']
createModelFormula <- function(targetVar, xVars, includeIntercept = TRUE){
if(includeIntercept){
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ ')))
} else {
modelForm <- as.formula(paste(targetVar, "~", paste(xVars, collapse = '+ '), -1))
}
return(modelForm)
}
v <- [1,2,3]
v <- c(1,2,3)
v[-1]
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, modelxvars)
model_input <- glm(formula =  default.payment.next.month ~.  ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input['aic'])
}
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
names(creditcard_data)
names(creditcard_data)[-25]
xVars <- names(creditcard_data)[-25]
xVars
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, xvars)
model_input <- glm(formula =  default.payment.next.month ~.  ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input['aic'])
}
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
modelForm <- createModelFormula(target, xVars)
modelForm
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=train)
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, xvars)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input['aic'])
}
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1 <- backwards(train,xVars, target)
aiclist = c()
type(aiclist)
typeof(aiclist)
aiclist = c(1,2)
typeof(aiclist)
min(aiclist)
typeof(model$aic)
aiclist = c(1,2, model$aic)
typeof(aiclist)
min(aiclist)
aiclist <- c(aiclist, model$aic)
typeof(aiclist)
aiclist
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, xvars)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input['aic'])
}
print(typeof(aiclist))
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1 <- backwards(train,xVars, target)
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, xvars)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input['aic'])
}
print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1 <- backwards(train,xVars, target)
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, xvars)
print(modelForm)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input$aic)
}
print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
xVars <- names(creditcard_data)[-25]
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1 <- backwards(train,xVars, target)
xVars_v1
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, modelxvars)
print(modelForm)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input$aic)
}
print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars)
}
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1 <- backwards(train,xVars, target)
xVars_v1
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, modelxvars)
print(modelForm)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input$aic)
}
print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars, model_input)
}
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, modelxvars)
#print(modelForm)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input$aic)
}
#print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
return(xvars, model_input)
}
xVars <- names(creditcard_data)[-25]
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1, model_input <- backwards(train,xVars, target)
backwards <- function(data, xvars, target) {
aic = Inf
repeat {
aiclist = c()
for (i in 1:length(xvars)) {
modelxvars <- xvars[-i]
modelForm <- createModelFormula(target, modelxvars)
#print(modelForm)
model_input <- glm(modelForm ,
family=binomial(link='logit'),data=data)
aiclist = c(aiclist, model_input$aic)
}
#print(aiclist)
if (min(aiclist) < aic) {
aic = min(aiclist)
xvars = xvars[-which.min(aiclist)]
}
else
break
}
print(model_input$aic)
return(xvars)
}
#modelForm <- createModelFormula(target, xVars)
#model_input <- glm(modelForm ,
#                   family=binomial(link='logit'),data=train)
xVars_v1<- backwards(train,xVars, target)
library(stats)
null <- glm(formula =  target ~ 1  , family=binomial(link='logit'),data=train)
library(MASS)
step <- stepAIC(model, direction = "Forward")
step <- stepAIC(model, direction = "forward")
target
null <- glm(formula =  target~ 1 , family=binomial(link='logit'),data=train)
full <- glm(formula =  target~. , family=binomial(link='logit'),data=train)
full <- glm(formula =  default.payment.next.month ~.  , family=binomial(link='logit'),data=train)
step <- stepAIC(full, direction = "forward")
step$anova
null <- glm(formula =  default.payment.next.month ~ 1 , family=binomial(link='logit'),data=train)
step <- stepAIC(null, direction = "forward")
step$anova
null <- glm(formula =  default.payment.next.month ~ 1, family=binomial(link='logit'),data=train)
step(null, scope=list(lower=null, upper=full), direction="forward")
step(full, data=train, direction="backward")
?lars
library(glmnet)
# 9. Run lasso regression on the data set. Briefly discuss how you determined
# the appropriate tuning parameters.
install.packages("glmnet")
library(glmnet)
x <- model.matrix(default.payment.next.month~.,train)
y <- as.numeric(train$default.payment.next.month)
y
cv.out <- cv.glmnet(x,y,alpha=1,family=”binomial”,type.measure = “mse” )
cv.out <- cv.glmnet(x,y,alpha=1,family = "binomial" , type.measure = "mse" )
cv.out
plot(cv.out)
lambda_min <- cv.out$lambda.min
lambda_1se <- cv.out$lambda.1se
coef(cv.out,s=lambda_1se)
#get test data
x_test <- model.matrix(default.payment.next.month~.,test)
#predict class, type=”class”
lasso_prob <- predict(cv.out,newx = x_test,s=lambda_1se,type="response")
#translate probabilities to predictions
lasso_predict <- rep("neg",nrow(testset))
#translate probabilities to predictions
lasso_predict <- rep(1,nrow(test))
lasso_predict[lasso_prob>.5] <- 0
#confusion matrix
table(pred=lasso_predict,true=test$default.payment.next.month)
#accuracy
mean(lasso_predict==test$default.payment.next.month)
#translate probabilities to predictions
lasso_predict <- rep(0,nrow(test))
lasso_predict[lasso_prob>.5] <- 1
#confusion matrix
table(pred=lasso_predict,true=test$default.payment.next.month)
#accuracy
mean(lasso_predict==test$default.payment.next.month)
cv.ridge <- cv.glmnet(x, y, family='binomial', alpha=0, parallel=TRUE, standardize=TRUE, type.measure='auc')
plot(cv.ridge)
cv.ridge$lambda.min
cv.ridge$lambda.1se
coef(cv.ridge, s=cv.ridge$lambda.min)
ridge_prob <- predict(cv.out,newx = x_test,s=cv.ridge$lambda.1se,type="response")
#translate probabilities to predictions
ridge_predict <- rep(0,nrow(test))
ridge_predict[ridge_prob>.5] <- 1
#confusion matrix
table(pred=ridge_predict,true=test$default.payment.next.month)
# true
# pred    0    1
# 0 4580 1077
# 1   92  250
#accuracy
mean(ridge_predict==test$default.payment.next.month)
# 11. Run naive bayes on the data set.
library(e1071)
Naive_Bayes_Model=naiveBayes(default.payment.next.month ~., data=train)
summary(Naive_Bayes_Model)
NB_Predictions = predict(Naive_Bayes_Model, test[,-25])
table(NB_Predictions,test$default.payment.next.month)
mean(NB_Predictions==test$default.payment.next.month)
# 12. Build a decision tree to classify the customers as defaulted
# or not-defaulted. Plot the resulting tree. Discuss whether you
# feel this is a good model.
library(rpart)
modelForm <- createModelFormula(target, xVars)
fit <- rpart(modelForm,
data=train,
method="class")
fit
modelForm
library(rattle)
library(rpart.plot)
library(RColorBrewer)
install.packages("rattle")
library(rattle)
library(rpart.plot)
install.packages('rpart.plot')
install.packages('RColorBrewer')
install.packages("RColorBrewer")
library(rattle)
library(rpart.plot)
library(RColorBrewer)
fancyRpartPlot(fit)
fit <- rpart(default.payment.next.month~.,
data=train,
method="class")
fit
fancyRpartPlot(fit)
Prediction2 <- predict(fit, test[,-25], type = "class")
Actual <- test$default.payment.next.month
confusionMatrix(reference = Actual, data = Prediction2)
fit2 <- rpart(modelForm,
data=train,
method="class",
control=rpart.control(minsplit=2, cp=0))
fancyRpartPlot(fit2)
x = train
# We need to convert this to a factor, which is annoying
y = as.factor(train[, target])
trctrl <- trainControl(method = "repeatedcv"
, number = 10, repeats = 3
, classProbs = TRUE
, summaryFunction = twoClassSummary
)
fit3CV<- train(x = x
, y = y
, method = "rpart",
# This is telling caret to test 20 options of the
# hyperparameters (tuning variables) for this
# model. Supposedly caret should know for rpart
# what variables to tune. In practice, bugs are
# aplenty!
tuneLength=20,
metric="ROC",
trControl = trctrl)
# Let's try a random forest model.
#install.packages('randomForest')
library(randomForest)
# Notice how this takes significantly longer than fitting a
# decision tree, but still pretty fast!
fit4 <- randomForest(x = x, y = y
, data=train,
importance=TRUE,
# fit 2000 decision trees!
ntree=2000)
varImpPlot(fit4)
Prediction4 <- predict(fit4, test[,-25], type = "response")
Prediction4 <- predict(fit4, test, type = "response")
confusionMatrix(reference = Actual, data = Prediction4)
Prediction4 <- predict(fit4, test[,-25], type = "response")
x = train[,-25]
# Notice how this takes significantly longer than fitting a
# decision tree, but still pretty fast!
fit4 <- randomForest(x = x, y = y
, data=train,
importance=TRUE,
ntree=2000)
#varImpPlot(fit4)
Prediction2 <- predict(fit4, test[,-25], type = "response")
confusionMatrix(reference = Actual, data = Prediction2)
confusion1
step(full, data=train, direction="backward")
install.packages("rmarkdown")
library(rmarkdown)
getOption("repos")
r <- getOption("repos");
r["CRAN"] <- "https://cran.rstudio.com/"
options(repos=r)
install.packages("rmarkdown")
install.packages("rmarkdown")
plot(cars)
install.packages("stringi")
library(stringi)
